from fastapi import APIRouter, Depends
from pydantic import BaseModel
from fastapi.responses import JSONResponse
import re
import asyncio
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnableParallel, RunnablePassthrough
from langchain_core.tools import tool
from sqlalchemy.orm import Session
from app.models.kabis import Kabis
from app.models.libtau import Library
import time
from fastapi import HTTPException
from pydantic import BaseModel
from typing import List, Optional
from ...deps import get_retriever_dep, get_llm, get_book_retriever_dep
from app.models.chat import ChatHistory
router = APIRouter(prefix="/api", tags=["chat", "chat_card"])
from app.core.db import SessionLocal
import re
from fastapi.responses import StreamingResponse
from app.models.books import Document

def clean_context(text: str) -> str:
    """
    –£–¥–∞–ª—è–µ—Ç —Ä–∞–∑–¥–µ–ª—ã —Å–æ —Å–ø–∏—Å–∫–∞–º–∏ –ª–∏—Ç–µ—Ä–∞—Ç—É—Ä—ã –∏ –≤–Ω–µ—à–Ω–∏–º–∏ –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º–∏
    (–≤–∫–ª—é—á–∞—è '–°–ø–∏—Å–æ–∫ –ª–∏—Ç–µ—Ä–∞—Ç—É—Ä—ã', '–†–µ–∫–æ–º–µ–Ω–¥—É–µ–º–∞—è –ª–∏—Ç–µ—Ä–∞—Ç—É—Ä–∞', 'References' –∏ –∏—Ö –≤–∞—Ä–∏–∞–Ω—Ç—ã)
    –∏–∑ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –∫–Ω–∏–≥–∏.
    """
    # –°–Ω–∞—á–∞–ª–∞ –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º –ø—Ä–æ–±–µ–ª—ã (—á—Ç–æ–±—ã '–ª–∏—Ç–µ—Ä –∞—Ç—É—Ä–∞' —Å—Ç–∞–ª–æ '–ª–∏—Ç–µ—Ä–∞—Ç—É—Ä–∞')
    normalized = re.sub(r'\s+', ' ', text)

    # –£–¥–∞–ª—è–µ–º –≤—Å—ë, —á—Ç–æ –∏–¥—ë—Ç –ø–æ—Å–ª–µ —Ç–∏–ø–∏—á–Ω—ã—Ö –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤ —Å–ø–∏—Å–∫–æ–≤ –ª–∏—Ç–µ—Ä–∞—Ç—É—Ä—ã
    pattern = r'(?i)(—Å–ø–∏—Å–æ–∫\s+—Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–Ω–æ–π\s+–ª–∏—Ç–µ—Ä–∞—Ç—É—Ä—ã|—Å–ø–∏—Å–æ–∫\s+–ª–∏—Ç–µ—Ä–∞—Ç—É—Ä—ã|–æ—Å–Ω–æ–≤–Ω–∞—è\s+–ª–∏—Ç–µ—Ä–∞—Ç—É—Ä–∞|–¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è\s+–ª–∏—Ç–µ—Ä–∞—Ç—É—Ä–∞|–ª–∏—Ç–µ—Ä–∞—Ç—É—Ä–∞|references)\b.*'
    cleaned = re.sub(pattern, '', normalized)

    return cleaned.strip()


def get_db():
    db = SessionLocal()
    try:
        yield db
    finally:
        db.close()


class ChatHistoryItem(BaseModel):
    sessionId: str
    question: str
    answer: str
    tools_used: Optional[List[str]] = []
    timestamp: Optional[float] = None  # UNIX timestamp


def save_chat_history(db: Session, session_id: str, question: str, answer: str, tools_used: list[str]):
    item = ChatHistory(
        session_id=session_id,
        question=question,
        answer=answer,
        tools_used=tools_used,
        timestamp=time.time()
    )
    db.add(item)
    db.commit()
    db.refresh(item)
    return item


class ChatRequest(BaseModel):
    query: str
    k: int | None = None
    sessionId: Optional[str] = None  # –Ω–æ–≤–æ–µ –ø–æ–ª–µ


def _format_docs(docs, per_chunk_chars=800, max_chunks=5):
    lines = []
    for d in docs[:max_chunks]:
        m = d.metadata or {}
        title = m.get("title", "–∫–Ω–∏–≥–∞")
        # author = m.get("author", "–Ω–µ–∏–∑–≤–µ—Å—Ç–µ–Ω")
        # subject = m.get("subject")
        page = m.get("page", "?")
        text = (d.page_content or "")[:per_chunk_chars].strip()
        lines.append(f"[{title}, —Å—Ç—Ä. {page}] {text}")
        print(title, m.get("source"), text)
    return "\n\n".join(lines)


# ---- –ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç: –≤–µ–∫—Ç–æ—Ä–Ω—ã–π –ø–æ–∏—Å–∫ ----
@tool("vector_search", return_direct=False)
def vector_search(query: str, k: int = 5, retriever=None) -> str:
    """
    –ü–æ–∏—Å–∫ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤ —Ç–µ–∫—Å—Ç–∞ –≤ –±–∏–±–ª–∏–æ—Ç–µ–∫–µ –ø–æ —Å–º—ã—Å–ª–æ–≤–æ–º—É —Å—Ö–æ–¥—Å—Ç–≤—É.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –∫—É—Å–∫–∏ —Ç–µ–∫—Å—Ç–∞ —Å —É–∫–∞–∑–∞–Ω–∏–µ–º –∫–Ω–∏–≥–∏, –∞–≤—Ç–æ—Ä–∞ –∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã.
    """
    print("–í–µ–∫—Ç–æ—Ä–Ω—ã–π –ø–æ–∏—Å–∫")
    if retriever is None:
        return "Retriever –Ω–µ –ø–æ–¥–∫–ª—é—á—ë–Ω"
    docs = retriever.invoke(query, config={"k": k})
    return _format_docs(docs)


def _format_books(docs, max_items=None):
    lines = []
    limit = max_items or len(docs)   # –µ—Å–ª–∏ None ‚Üí –±–µ—Ä–µ–º –≤—Å–µ
    for d in docs[:limit]:
        m = d.metadata or {}
        title = m.get("title", "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –∫–Ω–∏–≥–∞")
        # subject = m.get("subject", "–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è")
        print(title, m.get("title"), m.get("id_book"))

        lines.append(f"üìò {title}\n")
    return "\n\n".join(lines)


@tool("book_search")
def book_search(query: str, k: int = 50, retriever=None) -> str:
    """
    –û–±–∑–æ—Ä–Ω—ã–π –ø–æ–∏—Å–∫ –ø–æ –∫–Ω–∏–≥–∞–º (—ç–º–±–µ–¥–¥–∏–Ω–≥–∏).
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –∫–Ω–∏–≥ (–º–Ω–æ–≥–æ).
    """
    print("–û–±–∑–æ—Ä–Ω—ã–π –ø–æ–∏—Å–∫")
    if retriever is None:
        return "Retriever –¥–ª—è –∫–Ω–∏–≥ –Ω–µ –ø–æ–¥–∫–ª—é—á—ë–Ω"

    docs = retriever.invoke(query, config={"k": k})
    return _format_books(docs, max_items=k)


# –≥–ª–æ–±–∞–ª—å–Ω—ã–π —Å–ª–æ–≤–∞—Ä—å –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –≤—Ä–µ–º–µ–Ω–∏ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –∑–∞–ø—Ä–æ—Å–∞
# –∫–ª—é—á: sessionId, –∑–Ω–∞—á–µ–Ω–∏–µ: timestamp –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –∑–∞–ø—Ä–æ—Å–∞
_last_request_time: dict[str, float] = {}

RATE_LIMIT_SECONDS = 5  # –∏–Ω—Ç–µ—Ä–≤–∞–ª –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏


@router.post("/chat", summary="–ß–∞—Ç —Å –ò–ò")
async def chat(req: ChatRequest,
               retriever=Depends(get_retriever_dep),
               book_retriever=Depends(get_book_retriever_dep),
               llm=Depends(get_llm),
               db: Session = Depends(get_db)):

    session_id = req.sessionId or "anonymous"

    vs_tool_used = []
    bs_tool_used = []

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ª–∏–º–∏—Ç–∞
    now = time.time()
    last_time = _last_request_time.get(session_id, 0)

    if now - last_time < RATE_LIMIT_SECONDS:
        return JSONResponse(
            {"error": f"–°–ª–∏—à–∫–æ–º —á–∞—Å—Ç—ã–µ –∑–∞–ø—Ä–æ—Å—ã. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —á–µ—Ä–µ–∑ {int(RATE_LIMIT_SECONDS - (now - last_time))} —Å–µ–∫."},
            status_code=429
        )

    _last_request_time[session_id] = now

    # tools
    vs_tool = lambda q, k=5: (vs_tool_used.append("vector_search") or vector_search.func(q, k, retriever=retriever))
    bs_tool = lambda q, k=100: (bs_tool_used.append("book_search") or book_search.func(q, k, retriever=book_retriever))

    # –û–±—â–∏–π —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç
    system_prompt = (
        "–¢—ã ‚Äî –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã–π –ø–æ–º–æ—â–Ω–∏–∫ –ø–æ –ø–æ–∏—Å–∫—É –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –≤ –∫–Ω–∏–≥–∞—Ö —É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç–∞ ¬´–¢—É—Ä–∞–Ω-–ê—Å—Ç–∞–Ω–∞¬ª.\n"
        "–û—Ç–≤–µ—á–∞–π —Å—Ç—Ä–æ–≥–æ –Ω–∞ –æ—Å–Ω–æ–≤–∞–Ω–∏–∏ —Ç–µ–∫—Å—Ç–∞ –∏–∑ —Ä–∞–∑–¥–µ–ª–∞ ¬´–ö–æ–Ω—Ç–µ–∫—Å—Ç¬ª, –≥–¥–µ —É–∫–∞–∑–∞–Ω—ã –∫–Ω–∏–≥–∏ –∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã.\n"
        "–ö–∞–∂–¥—ã–π —Ñ–∞–∫—Ç –∏–ª–∏ –≤—ã–≤–æ–¥ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ —Å–æ–ø—Ä–æ–≤–æ–∂–¥–∞–π —Å—Å—ã–ª–∫–æ–π –Ω–∞ –∏—Å—Ç–æ—á–Ω–∏–∫ –≤ —Ñ–æ—Ä–º–∞—Ç–µ:\n"
        "¬´(<i>–Ω–∞–∑–≤–∞–Ω–∏–µ –∫–Ω–∏–≥–∏</i>, —Å—Ç—Ä. N)¬ª.\n"
        "–ï—Å–ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –Ω–µ—Ç ‚Äî —á–µ—Å—Ç–Ω–æ —Å–æ–æ–±—â–∞–π: "
        "¬´–í –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–∞—Ö —É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç–∞ –¢—É—Ä–∞–Ω-–ê—Å—Ç–∞–Ω–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –Ω–µ—Ç.¬ª\n"
        "–§–æ—Ä–º–∞—Ç–∏—Ä—É–π –æ—Ç–≤–µ—Ç –≤ HTML —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º —Ç–µ–≥–æ–≤ (<p>, <ul>, <li>, <b>, <i>).\n"
        "–ù–µ –≤—ã–¥—É–º—ã–≤–∞–π –∫–Ω–∏–≥–∏ –∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã, –∏—Å–ø–æ–ª—å–∑—É–π —Ç–æ–ª—å–∫–æ —Ç–µ, —á—Ç–æ —É–∫–∞–∑–∞–Ω—ã –≤ —Ä–∞–∑–¥–µ–ª–µ ¬´–ö–æ–Ω—Ç–µ–∫—Å—Ç¬ª."
    )

    prompt = ChatPromptTemplate.from_messages([
        ("system", system_prompt),
        (
            "human",
            "–í–æ–ø—Ä–æ—Å —Å—Ç—É–¥–µ–Ω—Ç–∞: {question}\n\n"
            "–ö–æ–Ω—Ç–µ–∫—Å—Ç (—Ç–µ–∫—Å—Ç–æ–≤—ã–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã —Å —É–∫–∞–∑–∞–Ω–∏–µ–º –∫–Ω–∏–≥–∏ –∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã):\n{context}"
        ),
    ])

    # --- 1Ô∏è‚É£ –ü–µ—Ä–≤—ã–π –∑–∞–ø—Ä–æ—Å ‚Äî —á–µ—Ä–µ–∑ vector_search ---
    vector_chain = (
        RunnableParallel(
            question=RunnablePassthrough(),
            context=lambda q: clean_context(vs_tool(q, req.k or 5)),
        )
        | prompt
        | llm
    )
    vector_answer = vector_chain.invoke(req.query).content

    # --- 2Ô∏è‚É£ –í—Ç–æ—Ä–æ–π –∑–∞–ø—Ä–æ—Å ‚Äî —á–µ—Ä–µ–∑ book_search ---
    book_chain = (
        RunnableParallel(
            question=RunnablePassthrough(),
            context=lambda q: bs_tool(q, req.k or 100),
        )
        | prompt
        | llm
    )
    book_answer = book_chain.invoke(req.query).content

    # --- 3Ô∏è‚É£ –û–±—ä–µ–¥–∏–Ω—è–µ–º –æ—Ç–≤–µ—Ç—ã ---
    final_answer = (
        "<h3>–û—Ç–≤–µ—Ç –ø–æ –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–º –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º (–≤–µ–∫—Ç–æ—Ä–Ω—ã–π –ø–æ–∏—Å–∫):</h3>\n"
        f"{vector_answer}\n"
        "<hr>"
        "<h3>–û—Ç–≤–µ—Ç –ø–æ –∫–Ω–∏–≥–∞–º –±–∏–±–ª–∏–æ—Ç–µ–∫–∏:</h3>\n"
        f"{book_answer}"
    )

    # --- 4Ô∏è‚É£ –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –ë–î ---
    save_chat_history(
        db=db,
        session_id=session_id,
        question=req.query,
        answer=final_answer,
        tools_used=list(set(vs_tool_used + bs_tool_used)),
    )

    return {"reply": final_answer}


async def summarize_card(llm, req, card):
    key, value = card
    context = ''
    cards = {

    }
    for i in range(len(value["pages"])):
        context += "—Å—Ç—Ä." + str(value["pages"][i]) + "\n"
        context += "—Ñ—Ä–∞–≥–º–µ–Ω—Ç" + value["text_snippets"][i] + "\n"
    system_role = (
        "–¢—ã ‚Äî –∞–∫–∞–¥–µ–º–∏—á–µ—Å–∫–∏–π –ø–æ–º–æ—â–Ω–∏–∫. –ö—Ä–∞—Ç–∫–æ –æ–±—ä—è—Å–Ω–∏, "
        "–ø–æ—á–µ–º—É —ç—Ç–æ—Ç –∏—Å—Ç–æ—á–Ω–∏–∫ –º–æ–∂–µ—Ç –±—ã—Ç—å –ø–æ–ª–µ–∑–µ–Ω —Å—Ç—É–¥–µ–Ω—Ç—É –ø–æ –¥–∞–Ω–Ω–æ–º—É –≤–æ–ø—Ä–æ—Å—É."
        "–û—Ç–≤–µ—Ç –¥–∞–≤–∞–π –≤ —Ñ–æ—Ä–º–∞—Ç–µ: —Å—Ç—Ä. X - –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ. –ü–æ –≤—Å–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü–∞–º –ø–µ—Ä–µ–¥–∞–Ω–Ω—ã–µ —Ç–µ–±–µ."
    )
    human_msg = (
        f"–í–æ–ø—Ä–æ—Å: {req.query}\n\n"
        f"–ò—Å—Ç–æ—á–Ω–∏–∫: {value['title']}\n\n"
        f"–§—Ä–∞–≥–º–µ–Ω—Ç: {context}"
    )
    prompt = ChatPromptTemplate.from_messages([
        ("system", system_role),
        ("human", human_msg)
    ])
    response = await llm.ainvoke(prompt.format_messages())  # <-- async –≤—ã–∑–æ–≤
    return {
        'title': value["title"],
        'download_url': value['download_url'],
        "text_snippet": context,
        "summary": response.content
            }


@router.post("/chat_card", summary="–ß–∞—Ç —Å –∫–∞—Ä—Ç–æ—á–∫–∞–º–∏ –∫–Ω–∏–≥")
async def chat(req: ChatRequest,
               retriever=Depends(get_retriever_dep),
               book_retriever=Depends(get_book_retriever_dep),
               llm=Depends(get_llm),
               db: Session = Depends(get_db)):

    session_id = req.sessionId or "anonymous"

    now = time.time()
    last_time = _last_request_time.get(session_id, 0)
    if now - last_time < RATE_LIMIT_SECONDS:
        return JSONResponse(
            {"error": f"–°–ª–∏—à–∫–æ–º —á–∞—Å—Ç—ã–µ –∑–∞–ø—Ä–æ—Å—ã. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —á–µ—Ä–µ–∑ {int(RATE_LIMIT_SECONDS - (now - last_time))} —Å–µ–∫."},
            status_code=429
        )
    _last_request_time[session_id] = now

    # --- BOOK SEARCH ---
    book_docs = book_retriever.invoke(req.query, config={"k": 10})
    id_books = [d.metadata.get("id_book") for d in book_docs if d.metadata]
    with SessionLocal() as session:
        kabis_records = session.query(Kabis).filter(Kabis.id_book.in_(id_books)).all()
        kb_map = [
            {
                "Language": k.lang,
                "title": f"{k.author} {k.title}",
                "pub_info": k.pub_info,
                "year": k.year,
                "subjects": k.subjects,
                "source": "book_search"
            }
            for k in kabis_records
        ]

    # --- VECTOR SEARCH ---
    vec_docs = retriever.invoke(req.query, config={"k": req.k or 5})

    vector_cards_dictionary = {}

    for d in vec_docs:
        m = d.metadata or {}
        id_book = m.get("id_book")
        if id_book in vector_cards_dictionary:
            text_snippet = (d.page_content or "")[:600].strip()
            page = m.get("page")
            vector_cards_dictionary[id_book]['pages'].append(page)
            vector_cards_dictionary[id_book]['text_snippets'].append(text_snippet)
        else:
            text_snippet = (d.page_content or "")[:600].strip()
            page = m.get("page")
            vector_cards_dictionary[id_book] = {
                "pages": [page],
                "text_snippets": [text_snippet],
            }

    id_books = [d.metadata.get("doc_id") for d in vec_docs if d.metadata]
    with SessionLocal() as session:
        documents = session.query(Document).filter(Document.id.in_(id_books)).all()
        for doc in documents:
            print(doc.source, doc.source == "library")
            if doc.source == 'kabis':
                record = session.query(Kabis).filter_by(id=doc.id_book).first()

                vector_cards_dictionary[doc.id_book]["title"] = record.title or record.author
                vector_cards_dictionary[doc.id_book]["language"] = record.lang
                vector_cards_dictionary[doc.id_book]["pub_info"] = record.pub_info
                vector_cards_dictionary[doc.id_book]["subjects"] = record.subjects
                vector_cards_dictionary[doc.id_book]["download_url"] = record.download_url
            elif doc.source == 'library':
                record = session.query(Library).filter_by(id=doc.id_book).first()

                vector_cards_dictionary[doc.id_book]["title"] = record.title
                vector_cards_dictionary[doc.id_book]["download_url"] = record.download_url

    semaphore = asyncio.Semaphore(3)

    async def summarize_card_limited(llm, req, card):
        async with semaphore:
            return await summarize_card(llm, req, card)

    tasks = [summarize_card_limited(llm, req, card) for card in vector_cards_dictionary.items()]
    annotated_vector_cards = await asyncio.gather(*tasks)

    save_chat_history(
        db=db,
        session_id=session_id,
        question=req.query,
        answer="",
        tools_used=["book_search", "vector_search"]
    )

    return {
        "reply": "–í –±–∏–±–ª–∏–æ—Ç–µ–∫–µ –Ω–∞–π–¥–µ–Ω—ã —Å–ª–µ–¥—É—é—â–∏–µ –∫–Ω–∏–≥–∏: ",
        "book_search": kb_map,
        "vector_search": annotated_vector_cards
    }


class LLMContextRequest(BaseModel):
    text_snippet: str
    title: str
    query: str
@router.post("/generate_llm_context")
async def generate_llm_context(request: LLMContextRequest):
    async def text_stream():
        system_role = (
            "–¢—ã ‚Äî –∞–∫–∞–¥–µ–º–∏—á–µ—Å–∫–∏–π –ø–æ–º–æ—â–Ω–∏–∫. –ö—Ä–∞—Ç–∫–æ –æ–±—ä—è—Å–Ω–∏, "
            "–ø–æ—á–µ–º—É —ç—Ç–æ—Ç –∏—Å—Ç–æ—á–Ω–∏–∫ –º–æ–∂–µ—Ç –±—ã—Ç—å –ø–æ–ª–µ–∑–µ–Ω —Å—Ç—É–¥–µ–Ω—Ç—É –ø–æ –¥–∞–Ω–Ω–æ–º—É –≤–æ–ø—Ä–æ—Å—É. "
            "–û—Ç–≤–µ—Ç –¥–∞–≤–∞–π –≤ —Ñ–æ—Ä–º–∞—Ç–µ: —Å—Ç—Ä. X - –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ. –ü–æ –≤—Å–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü–∞–º –ø–µ—Ä–µ–¥–∞–Ω–Ω—ã–µ —Ç–µ–±–µ."
        )
        human_msg = (
            f"–í–æ–ø—Ä–æ—Å: {request.query}\n\n"
            f"–ò—Å—Ç–æ—á–Ω–∏–∫: {request.title}\n\n"
            f"–§—Ä–∞–≥–º–µ–Ω—Ç: {request.text_snippet}"
        )

        prompt = ChatPromptTemplate.from_messages([
            ("system", system_role),
            ("human", human_msg)
        ])

        llm = get_llm()

        # –†–µ–∞–ª—å–Ω—ã–π —Å—Ç—Ä–∏–º–∏–Ω–≥ –æ—Ç LLM:
        async for chunk in llm.astream(prompt.format_messages()):
            if chunk.content:
                yield chunk.content

    return StreamingResponse(text_stream(), media_type="text/plain")
